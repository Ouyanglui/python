{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "import jieba\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    " 特征提取练习：文本特征抽取"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dislike', 'is', 'life', 'long', 'need', 'not', 'python', 'short', 'too']\n",
      "--------------------------------------------------\n",
      "  (0, 2)\t2\n",
      "  (0, 1)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 5)\t2\n",
      "  (1, 0)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 3)\t1\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[0 1 2 0 1 0 1 1 0]\n",
      " [1 1 1 0 0 2 1 1 0]\n",
      " [0 1 1 1 0 0 0 0 1]]\n",
      "[array(['life', 'is', 'short', 'need', 'python'], dtype='<U7'), array(['life', 'is', 'short', 'python', 'not', 'dislike'], dtype='<U7'), array(['life', 'is', 'too', 'long'], dtype='<U7')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\life\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def couvec():\n",
    "    # min_df：每个单词在文本中出现的次数\n",
    "    vec = CountVectorizer() # min_df=2:'is', 'life', 'python', 'short']\n",
    "    # fit_transform():转换数据  默认单字母的字符串不输出(类似i，a)\n",
    "    # 三个样本\n",
    "    res = vec.fit_transform([\n",
    "        'Life is short, u need python life',\n",
    "        'life is not short, u not dislike python',\n",
    "        'life is too long'])\n",
    "    # 打印分离出来的每一个值:符合出现次数的字符\n",
    "    print(vec.get_feature_names())\n",
    "    print('-'*50)\n",
    "    # 输出样本字符的稀疏矩阵(词频)\n",
    "    print(res)\n",
    "    print(type(res))\n",
    "    print(res.toarray())\n",
    "    # 把样本的特征和矩阵里的词频对应\n",
    "    print(vec.inverse_transform(res))\n",
    "\n",
    "couvec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['need', 'python', '人生', '人生漫漫', '孤岛上', '苦短', '迎接黎明']\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 1)\t2\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 0)\t1\n",
      "[[0 2 0 1 1 0 1]\n",
      " [1 1 1 0 0 1 0]]\n",
      "[array(['人生漫漫', '孤岛上', '迎接黎明', 'python'], dtype='<U6'), array(['python', '人生', '苦短', 'need'], dtype='<U6')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\life\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 汉字文本数值化\n",
    "def countvec():\n",
    "    # 汉字特征值化，单个汉字字母都不统计，因为无意义\n",
    "    ve = CountVectorizer()\n",
    "    data = ve.fit_transform(['人生漫漫，我 在 孤岛上 迎接黎明， python python',\n",
    "                             '人生 苦短，u need python'])\n",
    "    print(ve.get_feature_names())\n",
    "    print(data)\n",
    "    print(data.toarray())\n",
    "    print(ve.inverse_transform(data))\n",
    "\n",
    "countvec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "--------------------------------------------------\n",
      "地 也 ， 你 不分 好歹 何为 地 ？ 天业 ， 你 错堪 贤愚 枉 作天 ！ 纸上 得来 终觉 浅 ， 绝知 此事 要 躬行 。 不畏 浮云 遮 望眼 ， 自缘身 在 最高层 。\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 34>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;28mprint\u001B[39m(cv\u001B[38;5;241m.\u001B[39mget_feature_names())\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28mprint\u001B[39m(cv\u001B[38;5;241m.\u001B[39minverse_transform(data))\n\u001B[1;32m---> 34\u001B[0m \u001B[43mhanzivec\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36mhanzivec\u001B[1;34m()\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28mprint\u001B[39m(cou1,cou2,cou3)\n\u001B[0;32m     27\u001B[0m cv \u001B[38;5;241m=\u001B[39m CountVectorizer()\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_feature_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     29\u001B[0m data \u001B[38;5;241m=\u001B[39m cv\u001B[38;5;241m.\u001B[39mfit_transform([cou1,cou2,cou3])\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28mprint\u001B[39m(data\u001B[38;5;241m.\u001B[39mtoarray())\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:88\u001B[0m, in \u001B[0;36mdeprecated._decorate_fun.<locals>.wrapped\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(fun)\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     87\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(msg, category\u001B[38;5;241m=\u001B[39m\u001B[38;5;167;01mFutureWarning\u001B[39;00m)\n\u001B[1;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fun(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1437\u001B[0m, in \u001B[0;36mCountVectorizer.get_feature_names\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1425\u001B[0m \u001B[38;5;129m@deprecated\u001B[39m(\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget_feature_names is deprecated in 1.0 and will be removed \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1427\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min 1.2. Please use get_feature_names_out instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1428\u001B[0m )\n\u001B[0;32m   1429\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_feature_names\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1430\u001B[0m     \u001B[38;5;124;03m\"\"\"Array mapping from feature integer indices to feature name.\u001B[39;00m\n\u001B[0;32m   1431\u001B[0m \n\u001B[0;32m   1432\u001B[0m \u001B[38;5;124;03m    Returns\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1435\u001B[0m \u001B[38;5;124;03m        A list of feature names.\u001B[39;00m\n\u001B[0;32m   1436\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1437\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_vocabulary\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [t \u001B[38;5;28;01mfor\u001B[39;00m t, i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocabulary_\u001B[38;5;241m.\u001B[39mitems(), key\u001B[38;5;241m=\u001B[39mitemgetter(\u001B[38;5;241m1\u001B[39m))]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:506\u001B[0m, in \u001B[0;36m_VectorizerMixin._check_vocabulary\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    504\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_vocabulary()\n\u001B[0;32m    505\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfixed_vocabulary_:\n\u001B[1;32m--> 506\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVocabulary not fitted or provided\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocabulary_) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    509\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVocabulary is empty\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNotFittedError\u001B[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "# jieba中文分词\n",
    "def cutword():\n",
    "    word1 = jieba.cut('地也，你不分好歹何为地？天业，你错堪贤愚枉作天！')\n",
    "    word2 = jieba.cut('纸上得来终觉浅，绝知此事要躬行。')\n",
    "    word3 = jieba.cut('不畏浮云遮望眼，自缘身在最高层。')\n",
    "    # 转换成列表\n",
    "    print(type(word1))\n",
    "    print('-'*50)\n",
    "    # 切好放在列表上\n",
    "    content1 = list(word1)\n",
    "    content2 = list(word2)\n",
    "    content3 = list(word3)\n",
    "    # print(content1)\n",
    "    # 列表打印成字符串\n",
    "    cou1 = ' '.join(content1)\n",
    "    cou2 = ' '.join(content2)\n",
    "    cou3 = ' '.join(content3)\n",
    "    return cou1,cou2,cou3\n",
    "\n",
    "def hanzivec():\n",
    "    '''\n",
    "    分词后中文特征值化\n",
    "    :return:\n",
    "    '''\n",
    "    cou1,cou2,cou3 = cutword()\n",
    "    print(cou1,cou2,cou3)\n",
    "    cv = CountVectorizer()\n",
    "    print(cv.get_feature_names())\n",
    "    data = cv.fit_transform([cou1,cou2,cou3])\n",
    "    print(data.toarray())\n",
    "    print(cv.inverse_transform(data))\n",
    "\n",
    "hanzivec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TF-IDF TF:词频。idf:逆文档频率，lg(总文档数量/该词出现的文档数量)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "--------------------------------------------------\n",
      "<class 'generator'>\n",
      "--------------------------------------------------\n",
      "地 也 ， 你 不分 好歹 何为 地 ？ 天业 ， 你 错堪 贤愚 枉 作天 ！ 纸上 得来 终觉 浅 ， 绝知 此事 要 躬行 。 不畏 浮云 遮 望眼 ， 自缘身 在 最高层 。\n",
      "<class 'list'>\n",
      "--------------------------------------------------\n",
      "['不分', '不畏', '何为', '作天', '天业', '好歹', '得来', '最高层', '望眼', '此事', '浮云', '纸上', '终觉', '绝知', '自缘身', '贤愚', '躬行', '错堪']\n",
      "--------------------------------------------------\n",
      "[[0.37796447 0.         0.37796447 0.37796447 0.37796447 0.37796447\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.37796447 0.         0.37796447]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.40824829 0.         0.         0.40824829 0.         0.40824829\n",
      "  0.40824829 0.40824829 0.         0.         0.40824829 0.        ]\n",
      " [0.         0.4472136  0.         0.         0.         0.\n",
      "  0.         0.4472136  0.4472136  0.         0.4472136  0.\n",
      "  0.         0.         0.4472136  0.         0.         0.        ]]\n",
      "  (0, 3)\t0.37796447300922725\n",
      "  (0, 15)\t0.37796447300922725\n",
      "  (0, 17)\t0.37796447300922725\n",
      "  (0, 4)\t0.37796447300922725\n",
      "  (0, 2)\t0.37796447300922725\n",
      "  (0, 5)\t0.37796447300922725\n",
      "  (0, 0)\t0.37796447300922725\n",
      "  (1, 16)\t0.4082482904638631\n",
      "  (1, 9)\t0.4082482904638631\n",
      "  (1, 13)\t0.4082482904638631\n",
      "  (1, 12)\t0.4082482904638631\n",
      "  (1, 6)\t0.4082482904638631\n",
      "  (1, 11)\t0.4082482904638631\n",
      "  (2, 7)\t0.4472135954999579\n",
      "  (2, 14)\t0.4472135954999579\n",
      "  (2, 8)\t0.4472135954999579\n",
      "  (2, 10)\t0.4472135954999579\n",
      "  (2, 1)\t0.4472135954999579\n",
      "--------------------------------------------------\n",
      "[array(['作天', '贤愚', '错堪', '天业', '何为', '好歹', '不分'], dtype='<U3'), array(['躬行', '此事', '绝知', '终觉', '得来', '纸上'], dtype='<U3'), array(['最高层', '自缘身', '望眼', '浮云', '不畏'], dtype='<U3')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\life\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def tfidfvec():\n",
    "    # 评估文档重要程度\n",
    "\n",
    "   cou1,cou2,cou3 = cutword()\n",
    "   print(cou1,cou2,cou3)\n",
    "   print(type([cou1,cou2,cou3]))\n",
    "   tf = TfidfVectorizer()  # tf*idf\n",
    "   data = tf.fit_transform([cou1,cou2,cou3])\n",
    "   print('-'*50)\n",
    "   print(tf.get_feature_names())\n",
    "   print('-'*50)\n",
    "   print(data.toarray())\n",
    "   # 稀疏矩阵\n",
    "   print(data)\n",
    "   print('-'*50)\n",
    "   print(tf.inverse_transform(data))\n",
    "cutword()\n",
    "tfidfvec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "  特征处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -1.         -1.         -1.        ]\n",
      " [-1.          1.          1.          0.66666667]\n",
      " [-0.99997     0.          0.2         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 不同特征处理搞到同一个量纲上\n",
    "'''\n",
    "归一化处理:适用于传统精确数据场景\n",
    "缺点：受极值影响\n",
    "处理:x`=(x-min)/(max-min)\n",
    "归一化更换区间处理（-1，1）：x``=x`*(mx-mi)+mi mx-1,mi--1'''\n",
    "def mm():\n",
    "    mm = MinMaxScaler(feature_range=(-1,1)) # 归一化范围（0，1）\n",
    "    data = mm.fit_transform([[90, 2, 10, 40], [60, 4, 15, 45], [75, 3, 13, 46]])\n",
    "    print(data)\n",
    "    return None\n",
    "mm()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.41421354 -1.35873244  0.98058068]\n",
      " [-0.70731897  0.33968311  0.39223227]\n",
      " [-0.70689457  1.01904933 -1.37281295]]\n",
      "--------------------------------------------------------------------------------\n",
      "[3.33533333e+03 3.00000000e+00 1.33333333e+00]\n",
      "--------------------------------------------------------------------------------\n",
      "[2.22088916e+07 8.66666667e+00 2.88888889e+00]\n",
      "--------------------------------------------------------------------------------\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 标准化处理不同特征值到同一量纲\n",
    "def stand():\n",
    "    '''\n",
    "    通过对原始数据进行变化把数据变换到均值(期望)为0，标准差为1范围内\n",
    "    机器学习找的是分布规律\n",
    "    x`=(x-mean)/标准差\n",
    "    :return:\n",
    "    '''\n",
    "    std = StandardScaler()\n",
    "    data = std.fit_transform([[10000., -1., 3.], [2., 4., 2.], [4., 6., -1.]])\n",
    "    # 有异常极值后\n",
    "    print(data)\n",
    "    print('-'*80)\n",
    "    print(std.mean_)\n",
    "    print('-'*80)\n",
    "    print(std.var_)\n",
    "    print('-'*80)\n",
    "    print(std.n_samples_seen_)  # 样本数\n",
    "stand()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "缺失值处理（1.填补:Simplelmputer(均值，中值，众值，固定值);2.删除）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 3.]\n",
      " [7. 6.]\n",
      " [3. 2.]]\n"
     ]
    }
   ],
   "source": [
    "def im():\n",
    "    '''\n",
    "    缺失值处理：填补\n",
    "    :return:\n",
    "    '''\n",
    "    # NaN, nan,缺失值必须是这种形式，如果是？号(或者其他符号)，就要replace换成这种\n",
    "    im = SimpleImputer(missing_values=np.nan, strategy='median') # 策略替换：均值，中值，众值，固定值\n",
    "    data = im.fit_transform([[1, 2], [np.nan, 3], [7, 6], [3, 2]])\n",
    "    print(data)\n",
    "im()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "降维：特征数变少\n",
    "\n",
    "可以提高模型训练速度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 2]\n",
      " [1 4 1]\n",
      " [1 1 2]]\n",
      "The surport is [1 2 4]\n"
     ]
    }
   ],
   "source": [
    "def var():\n",
    "    var = VarianceThreshold(threshold=0)\n",
    "    # 删除方差小于等于0的特征\n",
    "    #默认只删除方差为0,threshold是方差阈值，删除比这个值小的那些特征\n",
    "    data = var.fit_transform([[0, 2, 0, 3,2],\n",
    "                              [0, 1, 4, 3,1],\n",
    "                              [0, 1, 1, 3,2]])\n",
    "    print(data)\n",
    "    # 获得被选择特征值的列编号\n",
    "    print('The surport is %s' % var.get_support(True))\n",
    "var()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}